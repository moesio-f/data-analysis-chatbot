services:
  ds_api:
    build:
      dockerfile: ./data-sources.Dockerfile
    environment:
      DATABASE_URL: "sqlite:///db.sqlite"
      TZ: "Brazil/East"
      PYTHONUNBUFFERED: 1
    command: ["--port", "80"]
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries", "1", "--spider", "http://0.0.0.0:80/healthcheck"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 40s
      start_interval: 1s
    restart: on-failure:3
    ports:
      - "8083:80"

  ollama:
    image: docker.io/ollama/ollama:latest
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    volumes:
      - ./ollama:/root/.ollama
    restart: on-failure:3
    ports:
      - 7869:11434
    deploy: # Remove if no GPU is available
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all 
              capabilities: [gpu]

  chatbot_api:
    build:
      dockerfile: ./chatbot.Dockerfile
    environment:
      DATA_SOURCE_URL: "http://ds_api:80/"
      MODEL: "gpt-oss:20b"
      PROVIDER: "ollama"
      OLLAMA_HOST: "ollama"
      TZ: "Brazil/East"
      PYTHONUNBUFFERED: 1
    command: ["--port", "80"]
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries", "1", "http://0.0.0.0:80/healthcheck"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 1m
      start_interval: 1s
    restart: on-failure:3
    ports:
      - "8082:80"
    depends_on:
      ollama:
        condition: service_started
      ds_api:
        condition: service_healthy

  dashboard:
    build:
      dockerfile: ./dashboard.Dockerfile
    environment:
      DATA_SOURCE_URL: "http://ds_api:80/"
      CHATBOT_URL: "http://chatbot_api:80/"
    command: ["--server.port", "80"]
    restart: on-failure:3
    ports:
       - "8081:80"
    depends_on:
      chatbot_api:
        condition: service_healthy
      ds_api:
        condition: service_healthy


